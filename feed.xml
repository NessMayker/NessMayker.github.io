<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://nessmayker.github.io/NessMaykerChen.github.io//feed.xml" rel="self" type="application/atom+xml" /><link href="https://nessmayker.github.io/NessMaykerChen.github.io//" rel="alternate" type="text/html" hreflang="en" /><updated>2023-06-29T22:30:19+00:00</updated><id>https://nessmayker.github.io/NessMaykerChen.github.io//feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">Produce Classifier</title><link href="https://nessmayker.github.io/NessMaykerChen.github.io//blog/2023/ProduceClassifier/" rel="alternate" type="text/html" title="Produce Classifier" /><published>2023-06-29T00:00:00+00:00</published><updated>2023-06-29T00:00:00+00:00</updated><id>https://nessmayker.github.io/NessMaykerChen.github.io//blog/2023/ProduceClassifier</id><content type="html" xml:base="https://nessmayker.github.io/NessMaykerChen.github.io//blog/2023/ProduceClassifier/"><![CDATA[<p>I started taking the Practical Deep Learning course from fast.ai (https://course.fast.ai/) and I have been so excited to practice what I have been learning.</p>

<p>For this project I am expanding on the Dog vs Cat classifier, instead training a model to classify fruit using the Fruits 360 dataset as my training data.</p>

<!-- <script type= "module"
src = "https://gradio.s3-us-west-2.amazonaws.com/3.12.0/gradio.js">
</script>

<gradio-app src="https://nessmaykerchen-produceclassifier.hf.space/"></gradio-app> -->

<iframe src="https://nessmaykerchen-produceclassifier.hf.space/" frameborder="0" width="850" height="550"></iframe>

<p>The fruits360 data set consists of 131 types of produce that are placed on a white background and have many images captured at different angles for each object. This is a decently sized training set with a total of 67,692 images, but the training set lacks diversity of different backgrounds and different groupings of multiple fruits.</p>

<p>To save time, I made a very basic model using the ResNet34 archetecture with a batch size of 16 and only one round of fine-tuning.</p>

<p>The first six example images are taken from the testing set, which the model was not allowed to interact with. As you can see the model performs brilliantly when tested with the same population of produce imaged with the same background.</p>

<p>The last two images are from a purple sweet potato I had at home. I tried to reproduce the white background for the first image, but it does have a different white balance. For the second image I used a noisy background to test how different the results would be. For the first sweet potato image, the model is split between 10 types of produce, with a preference toward labeling it as a red potato. Surprisingly, the model performed better for the second image with a split between only two types with a high certainty that it is a red potato. This is overall a good approximation considering there were no purple sweet potatoes in the training set.</p>

<p>The classifier performs much better when the images are very closely related to those in the training set. I am curious to know if the largest room for improvement in the model could be found by using a deeper neural net, or by introducing more diversity in the training set.</p>

<p>I definitely want to play around with this more in the future. For now, I need to pivot to NLP to keep up with the fast.ai course. :)</p>]]></content><author><name></name></author><category term="DeepLearning" /><category term="DeepLearning" /><category term="fastai" /><summary type="html"><![CDATA[A simple image classifier using fast.ai and the fruits360 dataset]]></summary></entry><entry><title type="html">Dog vs Cat</title><link href="https://nessmayker.github.io/NessMaykerChen.github.io//blog/2023/DogVsCat/" rel="alternate" type="text/html" title="Dog vs Cat" /><published>2023-06-28T00:00:00+00:00</published><updated>2023-06-28T00:00:00+00:00</updated><id>https://nessmayker.github.io/NessMaykerChen.github.io//blog/2023/DogVsCat</id><content type="html" xml:base="https://nessmayker.github.io/NessMaykerChen.github.io//blog/2023/DogVsCat/"><![CDATA[<p>I started taking the Practical Deep Learning course from fast.ai (https://course.fast.ai/).</p>

<p>The first two lessons introduce a simple image classifier that checks if an image is a cat or a dog. Followng the tutorial, I reproduce the classifier and make an interactive predicter using a huggingface space and gradio (https://huggingface.co/spaces/NessMaykerChen/CatVsDogClassifier).</p>

<!-- <script type= "module"
src = "https://gradio.s3-us-west-2.amazonaws.com/3.12.0/gradio.js">
</script>

<gradio-app src="https://nessmaykerchen-catvsdogclassifier.hf.space/"></gradio-app> -->

<iframe src="https://nessmaykerchen-catvsdogclassifier.hf.space/" frameborder="0" width="850" height="550"></iframe>

<p>The classifier performs well when the images are cats or dogs, but has not been trained to classify other images, so it basically tries to measure how dog like or cat like the rest of the examples are and returns some humourous results.</p>

<p>Iâ€™m looking forward to building more sophisticated image classifiers in the future!</p>]]></content><author><name></name></author><category term="DeepLearning" /><category term="DeepLearning" /><category term="fastai" /><summary type="html"><![CDATA[A simple image classifier using fast.ai]]></summary></entry></feed>